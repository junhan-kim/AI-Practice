{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns7GR0ZIl8e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpAQ6dcHl6yY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "    _learning_rate = 0.01\n",
        "    _max_iterations = 100000\n",
        "    _threshold = 0.01\n",
        "\n",
        "    def add_intercept(self, x_data):   # add intercept\n",
        "        intercept = np.ones((x_data.shape[0], 1))\n",
        "        return np.concatenate((intercept, x_data), axis=1)\n",
        "\n",
        "    def sigmoid(self, z):  # sigmoid function\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def cost(self, h, y):  # cost function\n",
        "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
        "\n",
        "    def fit(self, x_data, y_data):  # train datasets\n",
        "        num_examples, num_features = np.shape(x_data)\n",
        "\n",
        "        x_data = self.add_intercept(x_data)\n",
        "        self._W = np.zeros(x_data.shape[1])   # weights initialization\n",
        "\n",
        "        for i in range(100000):  # loop for 100000\n",
        "            z = np.dot(x_data, self._W)  # matrix multiplication\n",
        "            hypothesis = self.sigmoid(z)\n",
        "\n",
        "            diff = hypothesis - y_data  # diff between y_data and hypothesis\n",
        "            cost = self.cost(hypothesis, y_data)\n",
        "\n",
        "            # partial derivative of cost function : transposed x * diff / n\n",
        "            gradient = np.dot(x_data.transpose(), diff) / num_examples\n",
        "            self._W -= 0.01 * gradient   # update theta (learning rate : 0.01)\n",
        "\n",
        "            # stop learning when the threshold is reached\n",
        "            if cost < self._threshold:\n",
        "                return False\n",
        "            # print cost every 100 iter\n",
        "            if (i % 1000 == 0):\n",
        "                print('cost :', cost)\n",
        "\n",
        "    def predict_prob(self, x_data):\n",
        "        x_data = self.add_intercept(x_data)\n",
        "        return self.sigmoid(np.dot(x_data, self._W))\n",
        "\n",
        "    def predict(self, x_data):  # predict test datasets\n",
        "        return self.predict_prob(x_data).round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTpBF95-l_YK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine_data = pd.read_csv('winequality-white.csv',delimiter=';',dtype=float)\n",
        "print(wine_data.head(10))\n",
        "\n",
        "x_data = wine_data.iloc[:,0:-1]\n",
        "y_data = wine_data.iloc[:,-1]\n",
        "\n",
        "y_data = np.array([1 if i>=7 else 0 for i in y_data])\n",
        "x_data.head(5)\n",
        "\n",
        "train_x, test_x, train_y, test_y = sklearn.model_selection.train_test_split(x_data, y_data, test_size = 0.3,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZfiyuqomBlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(train_x, train_y)\n",
        "print('train completed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4WMG3vmDk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = lr.predict(test_x)\n",
        "print(\"Test Data\",sum(y_pred == test_y) / len(test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}