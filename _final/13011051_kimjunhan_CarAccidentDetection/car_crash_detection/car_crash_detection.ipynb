{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "car_crash_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTsge2sYxMVf",
        "colab_type": "text"
      },
      "source": [
        "# Car Crash Detection\n",
        "\n",
        "In each image frame, this application detects cars that have stopped for more than 10 seconds and recognizes as an accident if the car has been damaged.\n",
        "\n",
        "If this application is not checked for stopping status, the car running in state of damage may be recognized as accident car.\n",
        "\n",
        "I used a pre-learned base model for car detection. on the other hand, I learned the model for car damage detection. However, the code about training is the same as car fire module, so the code is not added here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6aaCklMt8qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "\n",
        "utils_ops.tf = tf.compat.v1\n",
        "tf.gfile = tf.io.gfile\n",
        "\n",
        "root = \".\"\n",
        "image_path = '/images'\n",
        "output_dir = './output_dir'\n",
        "\n",
        "def load_model_local(model_name):\n",
        "  model_dir = './model/' + model_name + '/saved_model'\n",
        "  model = tf.compat.v2.saved_model.load(str(model_dir), None)\n",
        "  model = model.signatures['serving_default']\n",
        "  return model\n",
        "\n",
        "# list of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = root + '_car_crash_detection/object_detection/data/kitti_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path(image_path)\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS\n",
        "\n",
        "# model for object detection (car)\n",
        "model_name = 'faster_rcnn_resnet101_kitti_2018_01_28'\n",
        "selected_model = load_model_local(model_name)\n",
        "\n",
        "# model for car crash check\n",
        "damage_model = load_model('./model/dense201_20epochs_6202_2071_model.h5')\n",
        "\n",
        "# this code block is referenced from tensorflow api\n",
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "  output_dict = model(input_tensor)\n",
        "\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict\n",
        "\n",
        "\n",
        "# count input images\n",
        "count = 0\n",
        "for path in pathlib.Path(image_path).iterdir():\n",
        "  if path.is_file():\n",
        "    count += 1\n",
        "print(count)\n",
        "\n",
        "check = 0\n",
        "temp = 0\n",
        "accident_flag = 0\n",
        "\n",
        "for i in range(count):\n",
        "  #feed test image\n",
        "  feed_image = np.array(Image.open(TEST_IMAGE_PATHS[i]))\n",
        "  output = run_inference_for_single_image(selected_model, feed_image)\n",
        "  \n",
        "  curcoord = list()\n",
        "  prevcoord = list()\n",
        "  diff = list()\n",
        "  last_idx = list()\n",
        "\n",
        "  if i == 0:\n",
        "    prevoutput = output\n",
        "  else:\n",
        "    for previ in range(prevoutput['num_detections']):  # for all of detected cars\n",
        "      if prevoutput['detection_scores'][previ] > 0.5:  # if detection score is larger than 0.5, \n",
        "        prevcoord = prevoutput['detection_boxes'][previ]  # previous coordinates is saved\n",
        "\n",
        "        for curi in range(output['num_detections']):\n",
        "          if output['detection_scores'][curi] > 0.5:\n",
        "            curcoord = output['detection_boxes'][curi]\n",
        "            diff = abs(curcoord - prevcoord)   # and yield diffence value with current and previous coordinate\n",
        "\n",
        "            # both values are smaller than 0.01 means this car object is not moved from previous frame\n",
        "            if diff[0] < 0.01 and diff[1] < 0.01:  \n",
        "              temp = 1\n",
        "              last_idx.append(curi)\n",
        "\n",
        "              \n",
        "  if temp == 1:\n",
        "    temp = 0\n",
        "    check += 1\n",
        "\n",
        "  if i%10 == 0:  # check every 10 steps\n",
        "    if check > 9:  # if car is stopped for 9 steps\n",
        "      print('stopped')\n",
        "      last_img = Image.open(TEST_IMAGE_PATHS[i])\n",
        "      width, height= last_img.size\n",
        "      print (width, height)\n",
        "      print(last_idx)\n",
        "      \n",
        "      for idx in last_idx:\n",
        "            # save cropped images x, y, height, width\n",
        "            crd_x = int(output['detection_boxes'][idx][1] * width)\n",
        "            crd_y = int(output['detection_boxes'][idx][0] * height)\n",
        "            crd_h = int(output['detection_boxes'][idx][2] * height)-int(output['detection_boxes'][idx][0] * height)\n",
        "            crd_w = int(output['detection_boxes'][idx][3]*width)-int(output['detection_boxes'][idx][1] * width)\n",
        "            area = (crd_x,crd_y,crd_x+crd_w,crd_y+crd_h)\n",
        "            size = crd_h*crd_w\n",
        "            if size > 8000:  # exclude objects that are too small because they are not recognized\n",
        "              print(area)\n",
        "              cropped_img = last_img.crop(area)\n",
        "              cropped_img.save('./cropped_images/' + 'croppedimage' + str(i) + '_' +str(idx) +  '.jpg')\n",
        "                     \n",
        "              test_img = cv2.imread(root + '/_car_crash_detection/cropped_images/' + 'croppedimage' + str(i) + '_' +str(idx) +  '.jpg')\n",
        "              test_img = cv2.resize(test_img,(160,160), interpolation =  cv2.INTER_CUBIC)\n",
        "              test_img = np.array(test_img)\n",
        "              test_img = np.expand_dims(test_img,axis=0)\n",
        "              test_img = test_img/255\n",
        "              \n",
        "              # predict car crash with cropped image\n",
        "              accident = damage_model.predict_classes(test_img)\n",
        "           \n",
        "              # if car crash is detected\n",
        "              if accident == 0:\n",
        "                print(\"accident is detected !!!\")     \n",
        "\n",
        "    check = 0        \n",
        "\n",
        "\n",
        "  prevoutput = output \n",
        "  print(i, check)\n",
        "\n",
        "  #load label (this code block is referenced from tensorflow api)\n",
        "  class_info = {}\n",
        "  f = open(root + '_car_crash_detection/class_info.txt', 'r')\n",
        "  for line in f:\n",
        "      info = line.split(', ')\n",
        "      class_index = int(info[0])\n",
        "      class_name = info[1]\n",
        "      color = (int(info[2][1:]), int(info[3]), int(info[4].strip()[:-1]))    \n",
        "      class_info[class_index] = [class_name, color]\n",
        "  f.close()\n",
        "\n",
        "  cv2.imwrite(output_dir + output_name + '.jpg', image)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}